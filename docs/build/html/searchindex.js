Search.setIndex({docnames:["contributing","description","examples","index","ipfml","ipfml/ipfml.exceptions","ipfml/ipfml.filters.convolution","ipfml/ipfml.filters.kernels","ipfml/ipfml.filters.noise","ipfml/ipfml.iqa.fr","ipfml/ipfml.metrics","ipfml/ipfml.processing.compression","ipfml/ipfml.processing.movement","ipfml/ipfml.processing.reconstruction","ipfml/ipfml.processing.segmentation","ipfml/ipfml.processing.transform","ipfml/ipfml.utils"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":2,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":1,"sphinx.ext.viewcode":1,sphinx:56},filenames:["contributing.rst","description.rst","examples.rst","index.rst","ipfml.rst","ipfml/ipfml.exceptions.rst","ipfml/ipfml.filters.convolution.rst","ipfml/ipfml.filters.kernels.rst","ipfml/ipfml.filters.noise.rst","ipfml/ipfml.iqa.fr.rst","ipfml/ipfml.metrics.rst","ipfml/ipfml.processing.compression.rst","ipfml/ipfml.processing.movement.rst","ipfml/ipfml.processing.reconstruction.rst","ipfml/ipfml.processing.segmentation.rst","ipfml/ipfml.processing.transform.rst","ipfml/ipfml.utils.rst"],objects:{"ipfml.filters":{convolution:[6,0,0,"-"],kernels:[7,0,0,"-"],noise:[8,0,0,"-"]},"ipfml.iqa":{fr:[9,0,0,"-"]},"ipfml.processing":{compression:[11,0,0,"-"],movement:[12,0,0,"-"],reconstruction:[13,0,0,"-"],segmentation:[14,0,0,"-"],transform:[15,0,0,"-"]},ipfml:{exceptions:[5,0,0,"-"],metrics:[10,0,0,"-"],utils:[16,0,0,"-"]}},objnames:{"0":["py","module","Python module"]},objtypes:{"0":"py:module"},terms:{"function":[6,7,8,9,10,11,12,13,14,15,16],"import":[1,2],"true":2,Using:3,about:0,after:2,all:[2,5,10,12,14],alreadi:2,appli:[2,6,7,8,12,14],assess:9,avail:2,below:2,bit:2,can:[2,12,15],chanel:2,comparison:10,compress:[3,13],contain:[5,10],content:3,contribut:3,convolut:[3,7],custom:5,descript:3,develop:3,document:[2,3],dure:3,each:2,exampl:3,except:3,extract:[11,15],file:0,filter:3,find:2,flip:12,flow:0,free:0,from:[1,2,15],fromarrai:2,full:9,fusion:12,gaussian:2,gaussian_nois:2,get_lab_l_svd_:1,git:0,github:3,guidelin:0,have:2,here:2,how:3,ident:2,imag:[1,2,6,7,8,9,11,12,13,14,15],image_natur:2,img:[1,2],img_path:2,impact:2,implement:0,index:3,inform:[0,2,15],instal:3,integr:16,ipfml:[1,2],iqa:3,jpg:2,just:1,kernel:3,low:2,low_bits_img:2,method:[9,13,14],metric:3,model:10,modul:[3,5],more:0,movement:3,natur:2,nois:3,noisy_imag:2,normal:16,now:2,onli:2,open:[1,2],other:2,output:2,packag:[1,2,3,5,16],page:3,path:[1,2],pictur:2,pil:[1,2],pip:1,pleas:0,png:1,process:[0,1],project:[0,3],python:3,qualiti:9,reconstruct:3,reduc:15,reduct:13,refer:[0,9],result:[2,10],rgb_to_grey_low_bit:2,rotat:12,same:2,search:3,segment:3,set:2,show:2,simpli:1,some:2,thesi:3,thi:[0,2],transform:[1,2,3],use:[2,3],used:[5,10,15],uses:0,using:[1,7,13],util:3,valu:2,want:0,which:[5,15],you:[0,2]},titles:["Contributing","Description","Examples","Image Processing For Machine Learning","Documentation","ipfml.exceptions","ipfml.filters.convolution","ipfml.filters.kernels","ipfml.filters.noise","ipfml.iqa.fr","ipfml.metrics","ipfml.processing.compression","ipfml.processing.movement","ipfml.processing.reconstruction","ipfml.processing.segmentation","ipfml.processing.transform","ipfml.utils"],titleterms:{For:3,Using:0,compress:11,contribut:0,convolut:6,descript:1,document:4,exampl:2,except:5,filter:[2,4,6,7,8],github:0,how:1,imag:3,indic:3,instal:1,ipfml:[3,4,5,6,7,8,9,10,11,12,13,14,15,16],iqa:[4,9],kernel:7,learn:3,machin:3,metric:10,movement:12,nois:[2,8],process:[2,3,4,11,12,13,14,15],reconstruct:13,segment:14,tabl:3,transform:15,use:1,util:16,what:3}})